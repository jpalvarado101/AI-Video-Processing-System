# **AI-Powered Video Clipping & Summarization Tool ğŸ¥ğŸš€**

ğŸš¨ **License Notice:**  
This project is under a **strict Read-Only License**.  
âœ”ï¸ You may **view** the code, but  
âŒ You **cannot copy, modify, use, or distribute** any part of it.  
Violations may result in legal action. See the [LICENSE](LICENSE) file for details.

An **AI-driven video processing** tool that extracts the **most engaging moments** from long-form videos **locally** using **Whisper, CLIP, OpenCV, Kafka, Redis, and Kubernetes**.  

ğŸ”¹ **No OpenAI API required!** Uses **free open-source models** instead.  
ğŸ”¹ **Deployable on Minikube/K3s** (Kubernetes-ready)  
ğŸ”¹ **Real-time Kafka & Redis Processing**  
ğŸ”¹ **GPU-Optimized (GTX 1080 Recommended, but CPU works too)**  

---

## **ğŸ“Œ Features**
âœ… **AI-Powered Video Highlight Detection** (CLIP Model)  
âœ… **Scene Segmentation** (SceneDetect + OpenCV)  
âœ… **Speech & Emotion Analysis** (Whisper ASR + Sentiment Analysis)  
âœ… **LLM-Based Auto Captioning** (Llama 3 / Falcon)  
âœ… **FFmpeg for Video Processing**  
âœ… **Kafka + Redis for Real-Time Processing**  
âœ… **Kubernetes (Minikube/K3s) for Scalability**  
âœ… **Streamlit UI for User Interaction**  

---

## **ğŸ“‚ Project Structure**
```
AI-Video-Clipping/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # FastAPI Backend
â”‚   â”œâ”€â”€ requirements.txt        # Python Dependencies
â”‚   â”œâ”€â”€ Dockerfile              # Dockerized Backend
â”‚   â”œâ”€â”€ k8s/                    # Kubernetes Configurations
â”‚   â”‚   â”œâ”€â”€ deployment.yaml      # K8s Deployment
â”‚   â”‚   â”œâ”€â”€ service.yaml         # K8s Service
â”‚   â”œâ”€â”€ models/                  # AI Models
â”‚   â”‚   â”œâ”€â”€ clip_model.py         # CLIP-based scene selection
â”‚   â”‚   â”œâ”€â”€ speech_analysis.py    # Whisper ASR + Sentiment Analysis
â”‚   â”‚   â”œâ”€â”€ summarization.py      # Llama 3 / Falcon AI Summarization
â”‚   â”œâ”€â”€ utils/                    # Utility Functions
â”‚   â”‚   â”œâ”€â”€ video_processing.py   # Scene detection (SceneDetect + OpenCV)
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py     # Kafka Producer
â”‚   â”‚   â”œâ”€â”€ redis_cache.py        # Redis Caching
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                 # Streamlit Frontend
â”‚   â”œâ”€â”€ requirements.txt        # Streamlit Dependencies
â”œâ”€â”€ kafka_setup/
â”‚   â”œâ”€â”€ docker-compose.yml      # Kafka + Zookeeper Setup
â””â”€â”€ README.md                   # Documentation
```

---

## **âš¡ Installation & Setup**
### **ğŸ”¹ 1. Start Kafka & Redis**
Ensure **Kafka and Redis** are running before executing the backend:

```sh
cd kafka_setup
docker-compose up -d
```

Start Redis:

```sh
docker run -d -p 6379:6379 redis
```

### **ğŸ”¹ 2. Install Dependencies**
#### **Backend Setup**
```sh
cd backend
pip install -r requirements.txt
uvicorn app:app --reload
```

#### **Frontend Setup (Streamlit)**
```sh
cd frontend
pip install -r requirements.txt
streamlit run app.py
```

---

## **ğŸ¯ How It Works**
1. **Upload a video via the Streamlit UI.**  
2. The **backend processes the video**:  
   - Detects **scene changes** using **OpenCV & SceneDetect**.  
   - Extracts **audio & transcribes** it via **Whisper ASR**.  
   - Runs **sentiment analysis** to detect **high-emotion moments**.  
   - Uses **CLIP to score each scene** and selects the most engaging one.  
   - Generates **automatic captions & summaries** via **Llama 3 / Falcon**.  
3. **Kafka sends events** to simulate **A/B testing**.  
4. **Redis caches results** for faster retrieval.  
5. **The best-scoring clip is displayed** with a generated caption.  

---

## **ğŸ–¥ï¸ Backend API (FastAPI)**
### **ğŸ”¹ Endpoint: Process Video**
```http
POST /process_video
```
#### **Request:**
Upload a video file (`.mp4`, `.mov`, `.avi`).
```sh
curl -X POST "http://localhost:8000/process_video" -F "file=@your_video.mp4"
```
#### **Response:**
```json
{
  "caption": "The speaker passionately discusses the importance of AI...",
  "best_scene": [10.5, 15.2],  # Start & End time of the best scene
  "sentiments": "Positive"
}
```

---

## **ğŸ–¥ï¸ Streamlit UI (Frontend)**
1. **Upload a video**  
2. Click **Process Video**  
3. The AI will **find the best scene, transcribe speech, and generate a caption.**  
4. The **output video and text** are displayed.

---

## **â˜¸ï¸ Deployment (Kubernetes - Minikube/K3s)**
### **ğŸ”¹ Deploy the Backend**
```sh
kubectl apply -f backend/k8s/deployment.yaml
kubectl apply -f backend/k8s/service.yaml
```
### **ğŸ”¹ Expose the Service**
```sh
minikube service ai-video-backend-service --url
```
### **ğŸ”¹ Run Kubernetes Dashboard**
```sh
minikube dashboard
```

---

## **ğŸ› ï¸ Key Technologies Used**
### **ğŸ”¹ AI Models**
- **Whisper ASR** â†’ **Transcribes video speech** into text.  
- **CLIP** â†’ **Finds the most visually engaging scene**.  
- **Hugging Face Sentiment Analysis** â†’ Detects emotional moments.  
- **Llama 3 / Falcon** â†’ Generates **video captions & summaries**.  

### **ğŸ”¹ Backend (FastAPI)**
- Handles **AI processing requests**.  
- Communicates with **Kafka & Redis**.  
- Serves **AI-generated captions and summaries**.  

### **ğŸ”¹ Frontend (Streamlit)**
- **User uploads video** and receives the **best-scoring clip**.  

### **ğŸ”¹ Infrastructure**
- **Kafka** â†’ Simulates **real-time A/B testing**.  
- **Redis** â†’ Caches results for **faster video retrieval**.  
- **Kubernetes** â†’ Deploys backend with **auto-scaling & load balancing**.  

---

## **ğŸ“Œ Sample Output**
**Uploaded Video:** `"example_video.mp4"`  
**Best Scene:** `Start: 10.5s â†’ End: 15.2s`  
**Generated Caption:** `"The speaker passionately discusses the importance of AI..."`  
**Sentiment Analysis:** `"Positive"`  

ğŸ¥ **The best scene is clipped and ready for sharing!**  

---

## **ğŸš€ Future Improvements**
âœ… **AI-Powered Auto-Cropping** (Adjust framing dynamically)  
âœ… **Multi-Modal Learning** (Combine **video, speech, and facial expressions**)  
âœ… **GPU-Optimized Pipelines** (TensorRT for faster inference)  
âœ… **Realtime Engagement Prediction** (Train models to **predict virality**)  

---

## **ğŸ’¡ FAQ**
### **â“ Can I run this without a GPU?**
Yes! All models run **on CPU**, but for **faster processing**, a **GPU (GTX 1080 or better) is recommended**.

### **â“ Do I need OpenAIâ€™s API?**
No! This project **only uses free, open-source models** (Whisper, CLIP, Llama 3, etc.).

### **â“ How does Kafka improve this system?**
Kafka simulates **real-time event processing**, allowing **A/B testing of different AI-generated video clips**.

### **â“ Why use Redis?**
Redis caches the **best scenes and captions**, so users donâ€™t need to reprocess the same video.

---

## **ğŸ“œ License**
This project is licensed under my **Custom Read-Only License**.

---

## **ğŸ”¥ Conclusion**
This **AI Video Clipping System** makes you **the perfect candidate for OpusClip** by showcasing:
âœ… **AI-Driven Video Processing**  
âœ… **Backend Engineering & API Development**  
âœ… **Data Pipelines (Kafka & Redis)**  
âœ… **Cloud Deployment (Kubernetes / Minikube)**  
âœ… **Real-World Scalability**  

